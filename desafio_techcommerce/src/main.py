"""
Pipeline Principal - TechCommerce DataOps
Executa todo o fluxo de qualidade de dados
"""

import sys
from pathlib import Path
import logging
from datetime import datetime

# Adicionar src ao path
sys.path.insert(0, str(Path(__file__).parent))

from pipeline_ingestao import DataIngestionPipeline
from great_expectations_setup import GreatExpectationsSetup
from expectation_suites import ExpectationSuites
from correcao_automatica import DataCleaner
from dashboard_qualidade import QualityDashboard
from sistema_alertas import AlertSystem

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


def print_banner(text: str):
    """Imprime banner formatado"""
    print("\n" + "=" * 80)
    print(f"  {text}")
    print("=" * 80 + "\n")


def main():
    """Executa pipeline completo de DataOps"""
    
    start_time = datetime.now()
    
    print_banner("üöÄ TECHCOMMERCE DATAOPS PIPELINE - INICIANDO")
    logger.info(f"In√≠cio: {start_time.strftime('%Y-%m-%d %H:%M:%S')}")
    
    try:
        # === ETAPA 1: SETUP GREAT EXPECTATIONS ===
        print_banner("üìä ETAPA 1/6: Setup Great Expectations")
        gx_setup = GreatExpectationsSetup()
        context = gx_setup.setup_all()
        logger.info("‚úì Great Expectations configurado")
        
        # === ETAPA 2: CRIAR EXPECTATION SUITES ===
        print_banner("üéØ ETAPA 2/6: Criando Expectation Suites (6 Dimens√µes)")
        suites = ExpectationSuites()
        suites.create_all_suites()
        logger.info("‚úì Todas as Expectation Suites criadas")
        
        # === ETAPA 3: INGEST√ÉO DE DADOS ===
        print_banner("üì• ETAPA 3/6: Ingest√£o de Dados")
        pipeline = DataIngestionPipeline()
        raw_datasets = pipeline.ingest_all()
        logger.info(f"‚úì {len(raw_datasets)} datasets ingeridos")
        
        # === ETAPA 4: CORRE√á√ÉO AUTOM√ÅTICA ===
        print_banner("üßπ ETAPA 4/6: Corre√ß√£o Autom√°tica de Dados")
        cleaner = DataCleaner()
        cleaned_datasets = cleaner.clean_all(
            raw_datasets['clientes_lab'],
            raw_datasets['produtos'],
            raw_datasets['vendas'],
            raw_datasets['logistica']
        )
        cleaner.save_cleaned_data(cleaned_datasets)
        logger.info("‚úì Dados limpos e salvos")
        
        # === ETAPA 5: DASHBOARD DE QUALIDADE ===
        print_banner("üìà ETAPA 5/6: Dashboard de Qualidade")
        dashboard = QualityDashboard()
        results = dashboard.run_full_pipeline()
        logger.info("‚úì Dashboard gerado")
        
        # === ETAPA 6: SISTEMA DE ALERTAS ===
        print_banner("üö® ETAPA 6/6: Sistema de Alertas")
        alert_system = AlertSystem()
        alerts = alert_system.process_alerts(results)
        logger.info(f"‚úì {len(alerts)} alertas processados")
        
        # === RESUMO FINAL ===
        end_time = datetime.now()
        duration = (end_time - start_time).total_seconds()
        
        print_banner("‚úÖ PIPELINE CONCLU√çDO COM SUCESSO")
        
        print("üìä RESUMO DA EXECU√á√ÉO:")
        print(f"   ‚Ä¢ Dura√ß√£o: {duration:.2f} segundos")
        print(f"   ‚Ä¢ Datasets processados: {len(raw_datasets)}")
        print(f"   ‚Ä¢ Datasets limpos: {len(cleaned_datasets)}")
        print(f"   ‚Ä¢ Expectation Suites: 4 (6 dimens√µes cada)")
        print(f"   ‚Ä¢ Checkpoints executados: 4")
        print(f"   ‚Ä¢ Alertas gerados: {len(alerts)}")
        print(f"   ‚Ä¢ Score de Qualidade: {results['summary']['success_rate']:.1f}%")
        
        print("\nüìÅ ARQUIVOS GERADOS:")
        print("   ‚Ä¢ Dados limpos: data/processed/")
        print("   ‚Ä¢ Data Docs: great_expectations/uncommitted/data_docs/")
        print("   ‚Ä¢ Relat√≥rios: data/quality/relatorio_qualidade_*.txt")
        print("   ‚Ä¢ M√©tricas: data/quality/metrics_latest.json")
        print("   ‚Ä¢ Alertas: data/quality/alertas_*.json")
        print("   ‚Ä¢ Logs: data/quality/pipeline.log")
        
        print("\nüéØ PR√ìXIMOS PASSOS:")
        print("   1. Revisar Data Docs no navegador")
        print("   2. Analisar relat√≥rio de qualidade")
        print("   3. Verificar alertas cr√≠ticos")
        print("   4. Implementar a√ß√µes corretivas")
        
        print("\n" + "=" * 80)
        logger.info(f"‚úì Pipeline conclu√≠do em {duration:.2f}s")
        
        return 0
        
    except Exception as e:
        print_banner("‚ùå ERRO NO PIPELINE")
        logger.error(f"Pipeline falhou: {str(e)}", exc_info=True)
        print(f"\n‚ùå Erro: {str(e)}")
        print("\nüí° Verifique:")
        print("   ‚Ä¢ Arquivos CSV est√£o em ../notebooks/datasets/")
        print("   ‚Ä¢ Great Expectations est√° instalado")
        print("   ‚Ä¢ Logs em data/quality/pipeline.log")
        return 1


if __name__ == "__main__":
    exit_code = main()
    sys.exit(exit_code)
